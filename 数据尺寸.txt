原视频尺寸：895 * 500 pxi  * 1013个

batchsize = 8
将每个视频读取为尺寸为 (frames, Height, Width, Channel）的图片（read_video)
接着抽帧采样为video_frames = 16帧图片
	现在的数据大小为：500 * 895 * 3 * 16 * 1013
	分别对应 ：(Height, Width, Channel, num_frames)
	调整维度为：(num_frames, Channel,  Height, Width)
将每一张图像转化为PIL格式进行如下变换
	dataset resize: frame * frame		3 * 500 * 895 → 3 * 128 * 128
	(totensor & 归一化)
	最后将这些图片堆叠起来：num_frames * 3 * 128 * 128
作为dataset创建dataloader
现在数据大小为：8 * num_frames * 3 * 128 * 128
分别对应：(batchsize, num_frames, Channel, Height, Width)

数据分批次进入模型：
    首先调整维度为 (batch_size, channels, num_frames, Height, Width)
    接着进行Embedding
        用三维卷积(conv_kernel=(1, 5, 5), stride=(1, 3, 3))：
            尺寸计算公式 conv_size = (frame_size - conv_kernel) / stride
        输出通道为d_model，尺寸为 8 * 512 * 16 * 42 * 42
        分别对应：(batch_size, d_model, num_frames, conv_height, conv_width)
        通过激活函数后进行三维池化(pool_kernel=(1, 2, 2), stride=(1, 2, 2))：
            尺寸计算公式 embedded_size = (conv_size - pool_kernel) / stride
        输出尺寸为 8 * 512 * 16 * 21 * 21
        分别对应：(batch_size, d_model, num_frames, embedded_height, embedded_width)
    从第三维度进行展平操作并调整维度为：8 * 16 * 441 * 512
    (batch_size, num_frames, embedded_HW, d_model)
    进行时空位置编码，尺寸不变
    进入Transformer Encoder：
        计算时空注意力:
            计算时间注意力时将空间项embedded_HW与Batch_size合并为一个维度只对时间项num_frames进行注意力计算：
            (batch_size * embedded_HW, num_frames, d_model)
            计算自注意力再将输出还原为：(batch_size, num_frames, embedded_HW, d_model)
            残差连接后紧凑；层归一化，尺寸不变

            计算时间注意力输出后，同样的将时间项num_frames与batch_size合并，只对空间项embedded_HW进行注意力计算
            (batch_size * num_frames, embedded_HW, num_frames, d_model)
            同样的计算自注意力后将尺寸还原，并进行残差连接和层归一化
        时空注意力计算不影响数据尺寸，所以输出仍是8 * 16 * 441 * 512

        经过SpatialTemporalAttention后对数据进行dropout操作以减少过拟合，并接残差连接和层归一化
        同样的这些操作也不改变数据尺寸，接着进入前向传播：在d_model维度上进行一个隐藏层的全连接处理
            d_model -> dim_feedforward -> d_model
        接着将前向传播的输出再进行dropout以及残差连接后输出，这样的映射不改变尺寸

        进行num_layers=6次的encoder_layers后输出
        即：(batch_size, num_frames, embedded_HW, d_model)
        接着进行时间和空间维度的池化操作降维，数据变为：8 * 512
        即：(batch_size, d_model)

        最后将数据通过分类器classifier：对d_model维度层归一化和与分类头全连接操作
        (batch_size, d_model) -> (batch_size, num_classes)
        最终返回为模型输出output。
